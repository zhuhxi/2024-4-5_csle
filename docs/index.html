---
layout: default
---

<div class="container">
    <div class="jumbotron bg-white text-center">
        <div class="container logoIndex">
            <img src="img/csle_logo_cropped.png" width="45%">
            <p class="lead ">A framework for building self-learning security systems.
            </p>
        </div>
    </div>

    <div class="container indexPageContainer">

        <h2 class="display text-left">What is CSLE?</h2>
        <p>
            CSLE is a framework for evaluating and developing reinforcement learning agents for control problems in
            cyber security.
            Everything from network emulation, to simulation, and learning in CSLE have been co-designed to provide an
            environment
            where it is possible to train and evaluate reinforcement learning agents for practical cyber security tasks.

            CSLE is an opinionated framework, which is based on a specific method for learning and evaluating security
            strategies for a given IT infrastructure (see Fig. 1).
        </p>
        <p class="csleFig">
            <img src="img/arch.png" width="60%">
            <p class="captionFig">Figure 1: The method used to automatically find effective security strategies in CSLE.</p>
        </p>

        <p>
            This method includes two systems: an emulation system and a simulation system.
            The emulation system closely approximates the functionality of the target infrastructure and
            is used to run attack scenarios and defender responses.
            Such runs produce system measurements and logs, from which infrastructure statistics are estimated,
            which then are used to instantiate Markov decision processes (MDPs).
        <p>

        <p>
            The simulation system is used to simulate the instantiated MDPs and to learn security strategies
            through reinforcement learning. Learned strategies are extracted from the simulation system and
            evaluated in the emulation system.
        <p>
        <p>
            Three benefits of this method are: (<span class="italicTxt">i</span>) that the emulation system provides
            a realistic environment to evaluate strategies; (<span class="italicTxt">ii</span>)
            that the emulation system allows evaluating strategies without affecting operational
            workflows on the target infrastructure; and (<span class="italicTxt">iii</span>) that the simulation
            system enables efficient and rapid learning of strategies.
        </p>

        <hr>
        <h2 class="display text-left">Why CSLE?</h2>
        <p>
            As the ubiquity and evolving nature of cyber attacks is of growing concern to society,
            <span class="italicTxt">automation</span> of security processes and functions has been recognized
            as an important part of the response to this threat. A promising approach to achieve this
            automation is <span class="italicTxt">reinforcement learning</span>,
            which has proven effective in finding near-optimal solutions to control problems
            in several domains (e.g., robotics and industry automation),
            and is actively investigated as an approach to automated security (see <a href="https://github.com/Limmen/awesome-rl-for-cybersecurity">survey</a>).
            While encouraging results have been obtained in this line of research, key challenges remain.
            Chief among them is narrowing the gap between the environment where the reinforcement learning agents
            are evaluated and a scenario playing out in a real system. Most of the results obtained so far are
            limited to simulation environments, and it is not clear how they generalize to practical
            IT infrastructures. Another limitation of prior research is the lack of common benchmarks and toolsets.
        </p>
        <p>
            CSLE was developed to address precisely the above limitations.
            By using high-fidelity emulations, it narrows the gap between the evaluation environment and a real system,
            and by being open-source, it provides a foundation for further research to build on.
        </p>
        <p>
            Recently, efforts to build similar frameworks as CSLE has started (see
            <a href="https://github.com/Limmen/awesome-rl-for-cybersecurity">survey</a>). Most notably, there is
            <a href="https://github.com/microsoft/CyberBattleSim">CyberBattleSim</a> by Microsoft,
            <a href="https://github.com/cage-challenge/CybORG">CyBorg</a> by
            the Australian department of defence, <a href="https://github.com/dstl/YAWNING-TITAN">Yawning Titan</a> by
            the UK Defence Science and Technology Laboratory (DSTL), and
            <a href="https://arxiv.org/pdf/2103.07583.pdf">FARLAND</a>
            , which is developed at USA's National Security Agency (NSA). Some of these frameworks only include
            simulation components and some of them include both simulation and emulation components.

            In contrast to these frameworks, CSLE is fully open-source,
            includes both a simulation component and an emulation component,
            and has demonstrated the capabilitiy to learn near-optimal defender strategies on specific use cases
            (see <a href="publications">publications</a>).
        </p>
        <hr>

        <h2 class="display text-left">Installation & Usage</h2>

        <p>
            CSLE is available for download on <a href="https://github.com/Limmen/csle">Github</a>
            The python APIs are available on <a href="https://pypi.org/user/Limmen/">PyPi</a>
            and can be installed using Pip. The Docker containers are available on
            <a href="https://hub.docker.com/r/kimham/"> Docker hub </a>.
            Detailed installation instructions can be found in the <a href="./docs/what-is-csle">documentation.</a>
        </p>

        <p>
            Examples of the four main usages of CSLE are given below:
            (1) data collection;
            (2) system identification;
            (3) strategy training; and
            (4), strategy evaluation.
        </p>

        <p>You can find additional examples in the <a href="./docs/what-is-csle">documentation.</a> and a video demonstration is
            available on <a href="https://www.youtube.com/watch?v=18P7MjPKNDg&t=1s">Youtube</a>.</p>

        <ul class="nav nav-tabs">
            <li class="active">
                <a href="#4" data-toggle="tab">Learn a security policy through RL</a>
            </li>
            <li><a href="#5" data-toggle="tab">Emulate intrusions and collect system traces</a>
            </li>
            <li><a href="#6" data-toggle="tab">Evaluate a learned strategy</a>
            </li>
            <li><a href="#7" data-toggle="tab">System identification</a>
            </li>
        </ul>
        <div id="usage" class="tab-content ">
            <div class="tab-pane active" id="4">
                {% highlight python %}
                # Imports
                import csle_common.constants.constants as constants
                from csle_common.dao.training.experiment_config import ExperimentConfig
                from csle_common.metastore.metastore_facade import MetastoreFacade
                from csle_common.dao.training.agent_type import AgentType
                from csle_common.dao.training.hparam import HParam
                from csle_common.dao.training.player_type import PlayerType
                from csle_agents.agents.ppo.ppo_agent import PPOAgent
                import csle_agents.constants.constants as agents_constants
                from csle_common.dao.training.tabular_policy import TabularPolicy

                # Select emulation configuration from the metastore
                emulation_env_config = MetastoreFacade.get_emulation_by_name("csle-level9-010")

                # Select simulation configuration from the metastore
                simulation_env_config = MetastoreFacade.get_simulation_by_name(
                                                   "csle-stopping-pomdp-defender-010")

                # Setup the reinforcement learning experiment
                experiment_config = ExperimentConfig(
                                  output_dir=f"{constants.LOGGING.DEFAULT_LOG_DIR}ppo_test",
                                  title="PPO test",
                                  random_seeds=[399, 98912, 999], agent_type=AgentType.PPO,
                                  log_every=1, hparams={..},
                                  player_type=PlayerType.DEFENDER, player_idx=0)
                agent = PPOAgent(emulation_env_config=emulation_env_config,
                simulation_env_config=simulation_env_config,
                experiment_config=experiment_config)

                # Run the PPO algorithm to learn defender policies
                experiment_execution = agent.train()

                # Save the experiment results and the learned policies
                MetastoreFacade.save_experiment_execution(experiment_execution)
                for policy in experiment_execution.result.policies.values():
                    MetastoreFacade.save_ppo_policy(ppo_policy=policy)
                {% endhighlight %}
            </div>

            <div class="tab-pane" id="5">
                {% highlight python %}
                # Imports
                import csle_common.constants.constants as constants
                from csle_common.dao.emulation_action.attacker.emulation_attacker_action import EmulationAttackerAction
                from csle_common.dao.emulation_action.defender.emulation_defender_action import EmulationDefenderAction
                from csle_common.dao.emulation_action.attacker.emulation_attacker_stopping_actions \
                import EmulationAttackerStoppingActions
                from csle_common.dao.emulation_action.defender.emulation_defender_stopping_actions \
                import EmulationDefenderStoppingActions
                from csle_common.dao.emulation_config.emulation_env_config import EmulationEnvConfig
                from csle_common.metastore.metastore_facade import MetastoreFacade
                from csle_common.controllers.container_controller import ContainerController
                from csle_system_identification.emulator import Emulator

                # Select an emulation execution
                executions = MetastoreFacade.list_emulation_executions_for_a_given_emulation(
                                            emulation_name="csle-level9-030")
                emulation_env_config = executions[0].emulation_env_config

                # Define attacker and defender sequences for the traces
                attacker_sequence = ...
                defender_sequence = ...

                # Run the sequences
                Emulator.run_action_sequences(
                        emulation_env_config=emulation_env_config,
                        attacker_sequence=attacker_sequence,
                        defender_sequence=defender_sequence, repeat_times=5000,
                        sleep_time=15,
                        descr="Intrusion data collected against novice attacker",
                        save_emulation_traces_every=1,
                        intrusion_start_p=0.2,
                        intrusion_continue=1)

                # Extract recorded traces and statistics
                statistics = MetastoreFacade.list_emulation_statistics()
                traces = MetastoreFacade.list_emulation_traces()
                {% endhighlight %}
            </div>

            <div class="tab-pane" id="6">
                {% highlight python %}
                # Imports
                import gymnasium as gym
                import csle_common.constants.constants as constants
                from csle_common.metastore.metastore_facade import MetastoreFacade
                from csle_common.dao.training.multi_threshold_stopping_policy import MultiThresholdStoppingPolicy
                from gym_csle_stopping_game.envs.stopping_game_pomdp_defender_env import StoppingGamePomdpDefenderEnv
                from csle_common.dao.training.player_type import PlayerType
                from csle_common.dao.training.agent_type import AgentType

                # Select emulation to be used as evaluation environment
                emulation_env_config = MetastoreFacade.get_emulation_by_name("..")

                # Select simulation environment
                simulation_env_config = MetastoreFacade.get_simulation_by_name("..")
                config = simulation_env_config.simulation_env_input_config
                env = gym.make(simulation_env_config.gym_env_name, config=config)

                # Define the security policy to evaluate
                tspsa_policy = MultiThresholdStoppingPolicy(..)

                # Perform the evaluation
                StoppingGamePomdpDefenderEnv.emulation_evaluation(
                           env=env, n_episodes=10, intrusion_seq=[..],
                           defender_policy=tspsa_policy,
                           emulation_env_config=emulation_env_config,
                           simulation_env_config=simulation_env_config)
                {% endhighlight %}
            </div>

            <div class="tab-pane" id="7">
                {% highlight python %}
                # Imports
                import csle_common.constants.constants as constants
                from csle_common.dao.system_identification.system_identification_config import SystemIdentificationConfig
                from csle_common.metastore.metastore_facade import MetastoreFacade
                from csle_common.dao.system_identification.system_model_type import SystemModelType
                from csle_common.dao.training.hparam import HParam
                from csle_system_identification.expectation_maximization.expectation_maximization_algorithm \
                import ExpectationMaximizationAlgorithm
                import csle_system_identification.constants.constants as system_identification_constants

                # Select emulation configuration from metastore
                emulation_env_config = MetastoreFacade.get_emulation_by_name("csle-level9-030")

                # Select emulation statistic (input data) from metastore
                emulation_statistic = MetastoreFacade.get_emulation_statistic(id=1)

                # Setup the system identification algorithm
                system_identifcation_config = SystemIdentificationConfig(
                                                 output_dir="..",
                                                 title="Expectation-Maximization level 9 test",
                                                 model_type=SystemModelType.GAUSSIAN_MIXTURE,
                                                 log_every=1,
                                                 hparams={..})
                algorithm = ExpectationMaximizationAlgorithm(
                                emulation_env_config=emulation_env_config,
                                emulation_statistics=emulation_statistic,
                                system_identification_config=system_identifcation_config)

                # Run the algorithm
                system_model = algorithm.fit()

                # Save the result to the metastore
                MetastoreFacade.save_gaussian_mixture_system_model(gaussian_mixture_system_model=system_model)
                {% endhighlight %}
            </div>
        </div>

    </div>

    <!--    <div id="exTab2" class="container indexPageContainer">-->

    <!--        <h2 class="display text-left">Installation</h2>-->
    <!--        <ul class="nav nav-tabs">-->
    <!--            <li class="active">-->
    <!--                <a href="#1" data-toggle="tab">Pip</a>-->
    <!--            </li>-->
    <!--            <li><a href="#2" data-toggle="tab">Docker</a>-->
    <!--            </li>-->
    <!--        </ul>-->
    <!--        <div class="tab-content" id="installation">-->
    <!--            <div class="tab-pane active" id="1">-->
    <!--                {% highlight bash %}-->
    <!--                pip install csle-collector \-->
    <!--                csle-common \-->
    <!--                csle-attacker \-->
    <!--                csle-defender \-->
    <!--                gym-csle-stopping-game \-->
    <!--                csle-system-identification \-->
    <!--                csle-agents \-->
    <!--                csle-ryu \-->
    <!--                csle-rest-api-->
    <!--                {% endhighlight %}-->
    <!--            </div>-->
    <!--            <div class="tab-pane" id="2">-->
    <!--                {% highlight bash %}-->
    <!--                TODO-->
    <!--                {% endhighlight %}-->
    <!--            </div>-->

    <!--        </div>-->


    <!--        <hr>-->
    <!--        <h2 class="display text-left">Usage</h2>-->
    <!--        <p>The example below demonstrates.. </p>-->
    <!--        <p>You can find additional examples in the <a href="/docs/">documentation </a> and a video demonstration is-->
    <!--            available on <a href="https://www.youtube.com/watch?v=18P7MjPKNDg&t=1s">Youtube</a>.</p>-->
    <!--    </div>-->
    <!--    <hr> -->

    <hr>

    <div class="row FeaturesRow">
        <div class="col-sm-4">
            <h1 class="text-center">
                <img src="img/mgmt_system.png" class="onlineLearningLogo" width="50%">
            </h1>
            <h4 class="text-center mgmtSystemText">Management System</h4>
            <p>
                The management system is the central component of CLSE and manages the overall execution of the framework.
                It is a distributed system that consist of N>=1 physical servers connected through an IP network.
                One of the servers is designated to be the "leader" and the other servers are "workers".

                The management system can be used to monitor emulations in real-time, to start or stop services,
                to monitor reinforcement learning workloads, to access terminals of emulated components,
                and to examine security policies.
            </p>
        </div>
        <div class="col-sm-4">
            <h1 class="text-center">
                <img src="img/emulation.png" class="emulationLogo" width="35%">
            </h1>
            <h4 class="text-center emulationText">Emulation System</h4>
            <p>
                The emulation system allows emulating large scale IT infrastructures and network traffic,
                i.e client traffic, cyber attacks, and automated defenses.
                It executes on a cluster of machines that runs a virtualization layer provided by Docker containers
                and virtual links. It implements network isolation and traffic shaping on the containers using
                network namespaces and the NetEm module in the Linux kernel. Resource constraints of the containers,
                e.g., CPU and memory constraints, are enforced using cgroups.
                <!--                Have a look at the <a href="https://github.com/Limmen/csle/examples">examples</a>.-->
            </p>
        </div>
        <div class="col-sm-4">
            <h1 class="text-center">
                <img src="img/rl.png" class="RlLogo" width="70%">
            </h1>
            <h4 class="text-center RlText">Simulation System</h4>
            <p>
                The simulation system of CSLE allows running reinforcement learning and optimization algorithms
                to learn security strategies. Formally, we model the interaction between an attacker and
                a defender as a Markov game. We then use simulations of self-play where autonomous agents interact and
                continuously update their strategies based on experience from previously played games.
                To automatically update strategies in the game, several methods can be used,
                including computational game theory, dynamic programming, evolutionary algorithms, and reinforcement
                learning.
            </p>
        </div>
    </div>
</div>
